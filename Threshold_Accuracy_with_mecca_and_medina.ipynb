{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEMiAuzOYS8NE6VLXerDn3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zihan07/Research-of-Semantic-similarity-between-Quran-verses-with-Biographies/blob/Final-Code-of-the-Research/Threshold_Accuracy_with_mecca_and_medina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgDi78eEfpAq",
        "outputId": "124dba8a-4fa3-4b53-917f-f6cc7c368281"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11**"
      ],
      "metadata": {
        "id": "zl2dH7g40G9S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vbJGW31fj1n",
        "outputId": "4d15513a-7736-41ec-88f5-9948f010fa8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        49.170000\n",
            "1  2nd Quartile (Q2, Median)        53.940000\n",
            "2          3rd Quartile (Q3)        58.520000\n",
            "3                    Average        54.244605\n",
            "Threshold 1: 49.17\n",
            "Threshold 2: 53.94\n",
            "Threshold 3: 58.52\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v1 b1.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v1 b1.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v1 b1.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v1 b1.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **13**"
      ],
      "metadata": {
        "id": "7qqP7uo90W3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v1 b3.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v1 b3.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v1 b3.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8T35SBZ0YIZ",
        "outputId": "bcaef43a-8d6a-4e5f-c700-935bec09b535"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        47.920000\n",
            "1  2nd Quartile (Q2, Median)        52.320000\n",
            "2          3rd Quartile (Q3)        56.660000\n",
            "3                    Average        52.549344\n",
            "Threshold 1: 47.92\n",
            "Threshold 2: 52.32\n",
            "Threshold 3: 56.66\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v1 b3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **15**"
      ],
      "metadata": {
        "id": "eTGoMroTDUJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v1 b5.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v1 b5.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v1 b5.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMSceE6H-pdC",
        "outputId": "5419f646-c8bd-40d5-8fe6-a08172b04690"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        46.940000\n",
            "1  2nd Quartile (Q2, Median)        51.020000\n",
            "2          3rd Quartile (Q3)        55.140000\n",
            "3                    Average        51.288604\n",
            "Threshold 1: 46.94\n",
            "Threshold 2: 51.02\n",
            "Threshold 3: 55.14\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v1 b5.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17**"
      ],
      "metadata": {
        "id": "qgDZmkQmDVzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v1 b7.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v1 b7.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v1 b7.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afFSxk9-AIvS",
        "outputId": "02788eaf-cecb-424e-8701-2aae762bcfdf"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        46.560000\n",
            "1  2nd Quartile (Q2, Median)        50.530000\n",
            "2          3rd Quartile (Q3)        54.860000\n",
            "3                    Average        50.972368\n",
            "Threshold 1: 46.56\n",
            "Threshold 2: 50.53\n",
            "Threshold 3: 54.86\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v1 b7.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **31**"
      ],
      "metadata": {
        "id": "ru09-q24AWf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v3 b1.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v3 b1.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v3 b1.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7sGwiWiAYYC",
        "outputId": "674be32a-b3af-40d7-c6cd-2a8272503b3c"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        49.800000\n",
            "1  2nd Quartile (Q2, Median)        53.480000\n",
            "2          3rd Quartile (Q3)        57.360000\n",
            "3                    Average        53.745594\n",
            "Threshold 1: 49.8\n",
            "Threshold 2: 53.48\n",
            "Threshold 3: 57.36\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v3 b1.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **33**"
      ],
      "metadata": {
        "id": "yAtmdTqRAiRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v3 b3.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v3 b3.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v3 b3.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNW1fe6hAjeJ",
        "outputId": "64a1c1d7-9527-4be2-d997-5a46808a5396"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        49.680000\n",
            "1  2nd Quartile (Q2, Median)        53.460000\n",
            "2          3rd Quartile (Q3)        57.407500\n",
            "3                    Average        53.725009\n",
            "Threshold 1: 49.68\n",
            "Threshold 2: 53.46\n",
            "Threshold 3: 57.4075\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v3 b3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **35**"
      ],
      "metadata": {
        "id": "BLPAg3_FAoYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v3 b5.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v3 b5.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v3 b5.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjmnNtIJApvA",
        "outputId": "1bdfcf6c-69fc-4f70-9323-6d1c654b5b88"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        49.047500\n",
            "1  2nd Quartile (Q2, Median)        52.760000\n",
            "2          3rd Quartile (Q3)        56.632500\n",
            "3                    Average        52.991801\n",
            "Threshold 1: 49.0475\n",
            "Threshold 2: 52.76\n",
            "Threshold 3: 56.6325\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v3 b5.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **37**"
      ],
      "metadata": {
        "id": "ijgAQ-XIAtox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v3 b7.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v3 b7.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v3 b7.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmeh7_l0AvGp",
        "outputId": "22c4dc2e-74ef-4b56-9bdb-d5dc89fc7266"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        48.720000\n",
            "1  2nd Quartile (Q2, Median)        52.480000\n",
            "2          3rd Quartile (Q3)        56.280000\n",
            "3                    Average        52.719795\n",
            "Threshold 1: 48.72\n",
            "Threshold 2: 52.48\n",
            "Threshold 3: 56.28\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v3 b7.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **51**"
      ],
      "metadata": {
        "id": "vCmquo_DA3v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v5 b1.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v5 b1.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v5 b1.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gvQDGntBCF4",
        "outputId": "19f23286-d4db-4dab-bc70-b7ff5deb510c"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        49.720000\n",
            "1  2nd Quartile (Q2, Median)        53.180000\n",
            "2          3rd Quartile (Q3)        56.715000\n",
            "3                    Average        53.373135\n",
            "Threshold 1: 49.72\n",
            "Threshold 2: 53.18\n",
            "Threshold 3: 56.715\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v5 b1.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **53**"
      ],
      "metadata": {
        "id": "YdrR0haDA6Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v5 b3.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v5 b3.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v5 b3.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaeM5ystA7w4",
        "outputId": "07bc5fbf-0bf2-4098-f6ac-453e2755201f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        50.120000\n",
            "1  2nd Quartile (Q2, Median)        53.690000\n",
            "2          3rd Quartile (Q3)        57.270000\n",
            "3                    Average        53.888682\n",
            "Threshold 1: 50.12\n",
            "Threshold 2: 53.69\n",
            "Threshold 3: 57.27\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v5 b3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **55**"
      ],
      "metadata": {
        "id": "W4VWr9EkBIZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v5 b5.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v5 b5.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v5 b5.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXlhfOmcBJlY",
        "outputId": "1347eaf3-63b9-4582-aae2-c28d44e4b70e"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        49.570000\n",
            "1  2nd Quartile (Q2, Median)        53.100000\n",
            "2          3rd Quartile (Q3)        56.670000\n",
            "3                    Average        53.332922\n",
            "Threshold 1: 49.57\n",
            "Threshold 2: 53.1\n",
            "Threshold 3: 56.67\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v5 b5.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **57**"
      ],
      "metadata": {
        "id": "KgkYuUvtBPnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v5 b7.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v5 b7.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v5 b7.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3WDj1X3BQ6g",
        "outputId": "9bf86a70-aace-4592-d472-ef08bb3bbc7d"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        49.240000\n",
            "1  2nd Quartile (Q2, Median)        52.820000\n",
            "2          3rd Quartile (Q3)        56.422500\n",
            "3                    Average        53.065639\n",
            "Threshold 1: 49.24\n",
            "Threshold 2: 52.82\n",
            "Threshold 3: 56.4225\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v5 b7.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **71**"
      ],
      "metadata": {
        "id": "DEh1JTMSBV_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v7 b1.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v7 b1.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v7 b1.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5RctEbsBXdQ",
        "outputId": "83d1ddd0-bf56-4e82-daf4-e31d032a7b92"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)         49.66000\n",
            "1  2nd Quartile (Q2, Median)         53.05000\n",
            "2          3rd Quartile (Q3)         56.58000\n",
            "3                    Average         53.26116\n",
            "Threshold 1: 49.66\n",
            "Threshold 2: 53.05\n",
            "Threshold 3: 56.58\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v7 b1.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **73**"
      ],
      "metadata": {
        "id": "OMEwNCdtBbZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v7 b3.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v7 b3.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v7 b3.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9hiHxFDBdJR",
        "outputId": "b5472ef9-2cc2-476f-f701-b227758c6129"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)         50.17000\n",
            "1  2nd Quartile (Q2, Median)         53.70000\n",
            "2          3rd Quartile (Q3)         57.25000\n",
            "3                    Average         53.91641\n",
            "Threshold 1: 50.17\n",
            "Threshold 2: 53.7\n",
            "Threshold 3: 57.25\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v7 b3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **75**"
      ],
      "metadata": {
        "id": "WbCFFWiPBjno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v7 b5.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v7 b5.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v7 b5.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYUxmf54BmUB",
        "outputId": "9f7a27b6-303d-4d64-d28a-daac783efdd3"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        49.750000\n",
            "1  2nd Quartile (Q2, Median)        53.230000\n",
            "2          3rd Quartile (Q3)        56.770000\n",
            "3                    Average        53.477612\n",
            "Threshold 1: 49.75\n",
            "Threshold 2: 53.23\n",
            "Threshold 3: 56.77\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v7 b5.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **77**"
      ],
      "metadata": {
        "id": "UiTYsXTQBqRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Mecca\n",
        "        TP_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FP_mecca = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN_mecca = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        # Confusion matrix for Medina\n",
        "        TP_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP_medina = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FN_medina = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "       # Precision, Recall, and F1 Score for Mecca\n",
        "        precision_mecca = TP_mecca / (TP_mecca + FP_mecca) if (TP_mecca + FP_mecca) > 0 else 0\n",
        "        recall_mecca = TP_mecca / (TP_mecca + FN_mecca) if (TP_mecca + FN_mecca) > 0 else 0\n",
        "        f1_mecca = 2 * (precision_mecca * recall_mecca) / (precision_mecca + recall_mecca) if (precision_mecca + recall_mecca) > 0 else 0\n",
        "\n",
        "        # Precision, Recall, and F1 Score for Medina\n",
        "        precision_medina = TP_medina / (TP_medina + FP_medina) if (TP_medina + FP_medina) > 0 else 0\n",
        "        recall_medina = TP_medina / (TP_medina + FN_medina) if (TP_medina + FN_medina) > 0 else 0\n",
        "        f1_medina = 2 * (precision_medina * recall_medina) / (precision_medina + recall_medina) if (precision_medina + recall_medina) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (Mecca)': precision_mecca,\n",
        "            'Recall (Mecca)': recall_mecca,\n",
        "            'F1 Score (Mecca)': f1_mecca,\n",
        "            'Precision (Medina)': precision_medina,\n",
        "            'Recall (Medina)': recall_medina,\n",
        "            'F1 Score (Medina)': f1_medina\n",
        "        }\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/v7 b7.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/C_v7 b7.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision (Mecca)': [metrics1['Precision (Mecca)'], metrics2['Precision (Mecca)'], metrics3['Precision (Mecca)']],\n",
        "    'Recall (Mecca)': [metrics1['Recall (Mecca)'], metrics2['Recall (Mecca)'], metrics3['Recall (Mecca)']],\n",
        "    'F1 Score (Mecca)': [metrics1['F1 Score (Mecca)'], metrics2['F1 Score (Mecca)'], metrics3['F1 Score (Mecca)']],\n",
        "    'Precision (Medina)': [metrics1['Precision (Medina)'], metrics2['Precision (Medina)'], metrics3['Precision (Medina)']],\n",
        "    'Recall (Medina)': [metrics1['Recall (Medina)'], metrics2['Recall (Medina)'], metrics3['Recall (Medina)']],\n",
        "    'F1 Score (Medina)': [metrics1['F1 Score (Medina)'], metrics2['F1 Score (Medina)'], metrics3['F1 Score (Medina)']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v7 b7.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssweuQyoBrhs",
        "outputId": "4333bd88-9c16-41b5-83b1-05d4bc2d4795"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        49.420000\n",
            "1  2nd Quartile (Q2, Median)        52.915000\n",
            "2          3rd Quartile (Q3)        56.560000\n",
            "3                    Average        53.209911\n",
            "Threshold 1: 49.42\n",
            "Threshold 2: 52.915\n",
            "Threshold 3: 56.56\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-MiniLM-L12-v2/O_v7 b7.xlsx\n"
          ]
        }
      ]
    }
  ]
}
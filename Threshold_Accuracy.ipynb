{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3n7gshW0PlNdxhsNlHfw3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zihan07/Research-of-Semantic-similarity-between-Quran-verses-with-Biographies/blob/Final-Code-of-the-Research/Threshold_Accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgDi78eEfpAq",
        "outputId": "abc6df94-4979-4a8d-f0e6-7a1b3c99b4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11**"
      ],
      "metadata": {
        "id": "zl2dH7g40G9S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vbJGW31fj1n",
        "outputId": "f44290c9-d4eb-4868-b527-80142ede41e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        52.070000\n",
            "1  2nd Quartile (Q2, Median)        57.400000\n",
            "2          3rd Quartile (Q3)        62.047500\n",
            "3                    Average        57.244386\n",
            "Threshold 1: 52.07\n",
            "Threshold 2: 57.4\n",
            "Threshold 3: 62.0475\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v1 b1.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v1 b1.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v1 b1.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v1 b1.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **13**"
      ],
      "metadata": {
        "id": "7qqP7uo90W3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v1 b3.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v1 b3.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v1 b3.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8T35SBZ0YIZ",
        "outputId": "a6deafd7-6e1b-4821-e5c2-59c7784badf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        50.500000\n",
            "1  2nd Quartile (Q2, Median)        55.775000\n",
            "2          3rd Quartile (Q3)        60.660000\n",
            "3                    Average        55.696574\n",
            "Threshold 1: 50.5\n",
            "Threshold 2: 55.77500000000001\n",
            "Threshold 3: 60.66\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v1 b3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **15**"
      ],
      "metadata": {
        "id": "eTGoMroTDUJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v1 b5.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v1 b5.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v1 b5.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMSceE6H-pdC",
        "outputId": "5fa249ff-d5d0-4bbf-c0cb-2c9390e2086c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        48.850000\n",
            "1  2nd Quartile (Q2, Median)        54.070000\n",
            "2          3rd Quartile (Q3)        58.970000\n",
            "3                    Average        54.096167\n",
            "Threshold 1: 48.85\n",
            "Threshold 2: 54.07\n",
            "Threshold 3: 58.97\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v1 b5.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17**"
      ],
      "metadata": {
        "id": "qgDZmkQmDVzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v1 b7.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v1 b7.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v1 b7.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afFSxk9-AIvS",
        "outputId": "217670db-66a3-42b1-e6c6-4c4c18184016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        47.925000\n",
            "1  2nd Quartile (Q2, Median)        52.890000\n",
            "2          3rd Quartile (Q3)        58.175000\n",
            "3                    Average        53.181733\n",
            "Threshold 1: 47.925\n",
            "Threshold 2: 52.89\n",
            "Threshold 3: 58.175\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v1 b7.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **31**"
      ],
      "metadata": {
        "id": "ru09-q24AWf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v3 b1.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v3 b1.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v3 b1.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7sGwiWiAYYC",
        "outputId": "5272f8e9-70f3-4dda-a2b0-80aabb17b1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        53.770000\n",
            "1  2nd Quartile (Q2, Median)        57.800000\n",
            "2          3rd Quartile (Q3)        61.690000\n",
            "3                    Average        57.739465\n",
            "Threshold 1: 53.77\n",
            "Threshold 2: 57.8\n",
            "Threshold 3: 61.69\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v3 b1.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **33**"
      ],
      "metadata": {
        "id": "yAtmdTqRAiRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v3 b3.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v3 b3.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v3 b3.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNW1fe6hAjeJ",
        "outputId": "4dbcb52d-3ca1-4b66-e263-fe603faa8307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        53.650000\n",
            "1  2nd Quartile (Q2, Median)        57.850000\n",
            "2          3rd Quartile (Q3)        61.962500\n",
            "3                    Average        57.763953\n",
            "Threshold 1: 53.65\n",
            "Threshold 2: 57.85\n",
            "Threshold 3: 61.9625\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v3 b3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **35**"
      ],
      "metadata": {
        "id": "BLPAg3_FAoYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v3 b5.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v3 b5.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v3 b5.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjmnNtIJApvA",
        "outputId": "7dcc0371-469b-48d0-ae3d-ad5983351777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        52.390000\n",
            "1  2nd Quartile (Q2, Median)        56.880000\n",
            "2          3rd Quartile (Q3)        61.020000\n",
            "3                    Average        56.680154\n",
            "Threshold 1: 52.39\n",
            "Threshold 2: 56.88\n",
            "Threshold 3: 61.02\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v3 b5.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **37**"
      ],
      "metadata": {
        "id": "ijgAQ-XIAtox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v3 b7.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v3 b7.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v3 b7.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmeh7_l0AvGp",
        "outputId": "3dfd7321-2186-432e-f2c3-7a02dc2a4f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        51.310000\n",
            "1  2nd Quartile (Q2, Median)        56.010000\n",
            "2          3rd Quartile (Q3)        60.690000\n",
            "3                    Average        55.969209\n",
            "Threshold 1: 51.31\n",
            "Threshold 2: 56.01\n",
            "Threshold 3: 60.69\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v3 b7.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **51**"
      ],
      "metadata": {
        "id": "vCmquo_DA3v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v5 b1.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v5 b1.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v5 b1.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gvQDGntBCF4",
        "outputId": "896033c3-120b-40af-c61b-c34ce27d9ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        54.470000\n",
            "1  2nd Quartile (Q2, Median)        58.110000\n",
            "2          3rd Quartile (Q3)        61.740000\n",
            "3                    Average        58.042164\n",
            "Threshold 1: 54.47\n",
            "Threshold 2: 58.11\n",
            "Threshold 3: 61.74\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v5 b1.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **53**"
      ],
      "metadata": {
        "id": "YdrR0haDA6Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v5 b3.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v5 b3.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v5 b3.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaeM5ystA7w4",
        "outputId": "0f063958-f0d3-4c14-a746-6fc9d4397ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        54.850000\n",
            "1  2nd Quartile (Q2, Median)        58.870000\n",
            "2          3rd Quartile (Q3)        62.550000\n",
            "3                    Average        58.656522\n",
            "Threshold 1: 54.85\n",
            "Threshold 2: 58.87\n",
            "Threshold 3: 62.55\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v5 b3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **55**"
      ],
      "metadata": {
        "id": "W4VWr9EkBIZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v5 b5.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v5 b5.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v5 b5.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXlhfOmcBJlY",
        "outputId": "5ae1f127-4557-4d9f-e048-a24abb9e1c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        54.050000\n",
            "1  2nd Quartile (Q2, Median)        58.130000\n",
            "2          3rd Quartile (Q3)        62.080000\n",
            "3                    Average        57.996787\n",
            "Threshold 1: 54.05\n",
            "Threshold 2: 58.13\n",
            "Threshold 3: 62.08\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v5 b5.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **57**"
      ],
      "metadata": {
        "id": "KgkYuUvtBPnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v5 b7.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v5 b7.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v5 b7.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3WDj1X3BQ6g",
        "outputId": "604b5b98-e3ed-41df-a0c0-56561191ae46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)         53.29000\n",
            "1  2nd Quartile (Q2, Median)         57.83500\n",
            "2          3rd Quartile (Q3)         61.88000\n",
            "3                    Average         57.54239\n",
            "Threshold 1: 53.29\n",
            "Threshold 2: 57.835\n",
            "Threshold 3: 61.88\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v5 b7.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **71**"
      ],
      "metadata": {
        "id": "DEh1JTMSBV_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v7 b1.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v7 b1.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v7 b1.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5RctEbsBXdQ",
        "outputId": "07abdf12-6f9e-4a38-87e9-5d16abda7bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        54.840000\n",
            "1  2nd Quartile (Q2, Median)        58.380000\n",
            "2          3rd Quartile (Q3)        61.830000\n",
            "3                    Average        58.260612\n",
            "Threshold 1: 54.84\n",
            "Threshold 2: 58.38\n",
            "Threshold 3: 61.83\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v7 b1.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **73**"
      ],
      "metadata": {
        "id": "OMEwNCdtBbZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v7 b3.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v7 b3.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v7 b3.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9hiHxFDBdJR",
        "outputId": "b4117a74-c078-4d6e-f6a5-cf4f69746957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        55.640000\n",
            "1  2nd Quartile (Q2, Median)        59.395000\n",
            "2          3rd Quartile (Q3)        63.020000\n",
            "3                    Average        59.237751\n",
            "Threshold 1: 55.64\n",
            "Threshold 2: 59.395\n",
            "Threshold 3: 63.02\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v7 b3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **75**"
      ],
      "metadata": {
        "id": "WbCFFWiPBjno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v7 b5.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v7 b5.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v7 b5.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYUxmf54BmUB",
        "outputId": "54689aa6-f7e1-4e9d-b023-ae2d91bc5a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)        55.055000\n",
            "1  2nd Quartile (Q2, Median)        58.970000\n",
            "2          3rd Quartile (Q3)        62.920000\n",
            "3                    Average        58.833212\n",
            "Threshold 1: 55.055\n",
            "Threshold 2: 58.97\n",
            "Threshold 3: 62.92\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v7 b5.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **77**"
      ],
      "metadata": {
        "id": "UiTYsXTQBqRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(df, threshold1, threshold2, threshold3):\n",
        "    # Filtering based on thresholds\n",
        "    df_filtered1 = df[df['Best Match Score (as percentage)'] >= threshold1]\n",
        "    df_filtered2 = df[df['Best Match Score (as percentage)'] >= threshold2]\n",
        "    df_filtered3 = df[df['Best Match Score (as percentage)'] >= threshold3]\n",
        "\n",
        "    def compute_metrics(df_filtered):\n",
        "        TP = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        TN = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "        FP = ((df_filtered['Actual Period'] == 'Medina') & (df_filtered['Predicted Period'] == 'Mecca')).sum()\n",
        "        FN = ((df_filtered['Actual Period'] == 'Mecca') & (df_filtered['Predicted Period'] == 'Medina')).sum()\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
        "\n",
        "    metrics1 = compute_metrics(df_filtered1)\n",
        "    metrics2 = compute_metrics(df_filtered2)\n",
        "    metrics3 = compute_metrics(df_filtered3)\n",
        "\n",
        "    return metrics1, metrics2, metrics3\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/v7 b7.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Load thresholds from the Excel sheet\n",
        "thresholds_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/C_v7 b7.xlsx'  # Replace with your thresholds file path\n",
        "thresholds_df = pd.read_excel(thresholds_file_path)\n",
        "\n",
        "# Debugging: Print the thresholds DataFrame to verify its structure\n",
        "print(\"Thresholds DataFrame:\")\n",
        "print(thresholds_df)\n",
        "\n",
        "# Extract thresholds from the second column (assuming the first column is an index or header)\n",
        "threshold1 = thresholds_df.iloc[0, 1]  # First row, second column\n",
        "threshold2 = thresholds_df.iloc[1, 1]  # Second row, second column\n",
        "threshold3 = thresholds_df.iloc[2, 1]  # Third row, second column\n",
        "\n",
        "# Debugging: Print the thresholds to verify\n",
        "print(f\"Threshold 1: {threshold1}\")\n",
        "print(f\"Threshold 2: {threshold2}\")\n",
        "print(f\"Threshold 3: {threshold3}\")\n",
        "\n",
        "# Evaluate with the thresholds from the Excel sheet\n",
        "metrics1, metrics2, metrics3 = evaluate_predictions(df, threshold1, threshold2, threshold3)\n",
        "\n",
        "# Create a DataFrame to store the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Threshold': [threshold1, threshold2, threshold3],\n",
        "    'Accuracy': [metrics1['Accuracy'], metrics2['Accuracy'], metrics3['Accuracy']],\n",
        "    'Precision': [metrics1['Precision'], metrics2['Precision'], metrics3['Precision']],\n",
        "    'Recall': [metrics1['Recall'], metrics2['Recall'], metrics3['Recall']],\n",
        "    'F1 Score': [metrics1['F1 Score'], metrics2['F1 Score'], metrics3['F1 Score']]\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file_path = '/content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v7 b7.xlsx'\n",
        "metrics_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssweuQyoBrhs",
        "outputId": "1d3ab1bc-245a-43ea-9eed-f64db943207a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholds DataFrame:\n",
            "                    Quartile  Threshold Value\n",
            "0          1st Quartile (Q1)         54.43000\n",
            "1  2nd Quartile (Q2, Median)         58.93000\n",
            "2          3rd Quartile (Q3)         62.94000\n",
            "3                    Average         58.58026\n",
            "Threshold 1: 54.43\n",
            "Threshold 2: 58.93\n",
            "Threshold 3: 62.94\n",
            "Metrics saved to /content/drive/MyDrive/Quran-vs-biography-semantic-similarity-CSE498/U_all-mpnet-base-v2/O_v7 b7.xlsx\n"
          ]
        }
      ]
    }
  ]
}